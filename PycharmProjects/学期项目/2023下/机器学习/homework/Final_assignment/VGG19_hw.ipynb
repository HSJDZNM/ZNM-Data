{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms as T\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_channels---输入维度\n",
    "# out_channels---输出维度\n",
    "# kernel_size---卷积核大小\n",
    "# stride---步长\n",
    "# padding---边缘填充\n",
    "# num_blocks---添加的层数\n",
    "# max_pooling---最大池化\n",
    "\n",
    "# 设置一个卷积层类\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1,\n",
    "                 padding=None, groups=1, activation=True):\n",
    "        super(Conv, self).__init__()\n",
    "        padding = kernel_size // 2 if padding is None else padding  # 来保持输入和输出的尺寸一致\n",
    "\n",
    "        # 定义一个2维卷积层\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride,\n",
    "                              padding, groups=groups, bias=True)\n",
    "        # 定义一个激活函数\n",
    "        self.act = nn.ReLU(inplace=True) if activation else nn.Identity()   # 如果activation为Ture则使用re正则化，反之使用恒等映射\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.conv(x))   # 卷积输出的值直接给激活函数进行激活，最后返回激活后的值\n",
    "\n",
    "# 构建 VGG19 模型\n",
    "class VGG19(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGG19, self).__init__()\n",
    "        \n",
    "        # 定义神经网络的各个阶段\n",
    "        self.stages = nn.Sequential(*[self._make_stage(784, 784, num_blocks=1, max_pooling=False, dropout=False),\n",
    "            self._make_stage(784, 392, num_blocks=1, max_pooling=False, dropout=False),\n",
    "            self._make_stage(392, 196, num_blocks=1, max_pooling=False, dropout=False),\n",
    "            self._make_stage(196, 92, num_blocks=1, max_pooling=False, dropout=False),]\n",
    "        )\n",
    "        \n",
    "        # 定义神经网络的头部（全连接层）\n",
    "        self.head = nn.Sequential(*[nn.Flatten(start_dim=1, end_dim=-1),\n",
    "            nn.Linear(92, 92),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(92, 46),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(46, 46),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(46, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, num_classes)]\n",
    "        )\n",
    "\n",
    "    # 定义一个静态方法\n",
    "    @staticmethod\n",
    "    def _make_stage(in_channels, out_channels, num_blocks, max_pooling, dropout):\n",
    "        # 定义一个VGG阶段，包括卷积层和（可选的）最大池化层\n",
    "        layers = [Conv(in_channels, out_channels, kernel_size=3, stride=1)]     # 创建了一个列表 layers，其中包含了阶段的第一个卷积层。\n",
    "\n",
    "        for _ in range(1, num_blocks):  # \"_\"符号的意思就是一个占位符，告诉阅读的人该变量在循环内没使用\n",
    "            layers.append(Conv(out_channels, out_channels, kernel_size=3, stride=1))\n",
    "\n",
    "        if max_pooling:     # 如果要使用最大池化就再模型里添加一层\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
    "        \n",
    "        # 再添加一层Dropout层\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(0.5))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数，将输入数据通过各个阶段和头部层\n",
    "        return self.head(self.stages(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Sequential: 2-1                   --\n",
      "|    |    └─Conv: 3-1                    5,532,688\n",
      "|    └─Sequential: 2-2                   --\n",
      "|    |    └─Conv: 3-2                    2,766,344\n",
      "|    └─Sequential: 2-3                   --\n",
      "|    |    └─Conv: 3-3                    691,684\n",
      "|    └─Sequential: 2-4                   --\n",
      "|    |    └─Conv: 3-4                    162,380\n",
      "├─Sequential: 1-2                        --\n",
      "|    └─Flatten: 2-5                      --\n",
      "|    └─Linear: 2-6                       8,556\n",
      "|    └─ReLU: 2-7                         --\n",
      "|    └─Linear: 2-8                       4,278\n",
      "|    └─ReLU: 2-9                         --\n",
      "|    └─Linear: 2-10                      2,162\n",
      "|    └─ReLU: 2-11                        --\n",
      "|    └─Linear: 2-12                      1,504\n",
      "|    └─ReLU: 2-13                        --\n",
      "|    └─Linear: 2-14                      330\n",
      "=================================================================\n",
      "Total params: 9,169,926\n",
      "Trainable params: 9,169,926\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Sequential: 1-1                        --\n",
       "|    └─Sequential: 2-1                   --\n",
       "|    |    └─Conv: 3-1                    5,532,688\n",
       "|    └─Sequential: 2-2                   --\n",
       "|    |    └─Conv: 3-2                    2,766,344\n",
       "|    └─Sequential: 2-3                   --\n",
       "|    |    └─Conv: 3-3                    691,684\n",
       "|    └─Sequential: 2-4                   --\n",
       "|    |    └─Conv: 3-4                    162,380\n",
       "├─Sequential: 1-2                        --\n",
       "|    └─Flatten: 2-5                      --\n",
       "|    └─Linear: 2-6                       8,556\n",
       "|    └─ReLU: 2-7                         --\n",
       "|    └─Linear: 2-8                       4,278\n",
       "|    └─ReLU: 2-9                         --\n",
       "|    └─Linear: 2-10                      2,162\n",
       "|    └─ReLU: 2-11                        --\n",
       "|    └─Linear: 2-12                      1,504\n",
       "|    └─ReLU: 2-13                        --\n",
       "|    └─Linear: 2-14                      330\n",
       "=================================================================\n",
       "Total params: 9,169,926\n",
       "Trainable params: 9,169,926\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG19(num_classes=10).to(device)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:10<00:00, 919321.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 764929.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1031294.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\mnist\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 设置批大小\n",
    "batch_size=32\n",
    "\n",
    "# 数据增强\n",
    "train_enhance = T.Compose([\n",
    "                    T.Resize((224,224)),            # 固定图像大小\n",
    "                    T.RandomHorizontalFlip(0.5),    # 随机数据水平翻转\n",
    "                    T.ToTensor()                    # 转换为torch接受的张量类型\n",
    "                    ])\n",
    "\n",
    "test_enhance = T.Compose([\n",
    "                    T.Resize((224,224)),\n",
    "                    T.ToTensor()\n",
    "                    ])\n",
    "\n",
    "# mnist数据集\n",
    "train_database = datasets.MNIST(root = r\"data\\mnist\",\n",
    "                                train = True, transform = train_enhance, download = True)\n",
    "\n",
    "test_database = datasets.MNIST(root = r\"data\\mnist\",\n",
    "                               train = False, transform=test_enhance, download = True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_database, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_database, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 224, 224])\n",
      "1875\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i[0].size())\n",
    "    break\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固定随机种子\n",
    "torch.manual_seed(-1)\n",
    "# 学习率\n",
    "learning_rate = 1e-5\n",
    "# 训练轮数\n",
    "num_epochs = 50\n",
    "# 优化算法Adam = RMSProp + Momentum (梯度、lr两方面优化下降更快更稳)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "# 交叉熵损失函数                                           \n",
    "loss_fn = torch.nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter,model):\n",
    "    '''\n",
    "        模型预测精度\n",
    "    '''\n",
    "    total = 0\n",
    "    correct = 0 \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images,labels in data_iter:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _,predicts = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicts == labels).cpu().sum()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader=train_loader, optimizer=optimizer, loss_fn=loss_fn, epochs=num_epochs, device=device):\n",
    "    for epoch in range(epochs):\n",
    "        print('当前训练周期 = {}'.format(epoch))\n",
    "        loop=tqdm((data_loader),total=len(data_loader))\n",
    "        for i, (images, labels) in enumerate(loop):\n",
    "            train_accuracy_total = 0\n",
    "            train_correct = 0\n",
    "            train_loss_sum = 0\n",
    "            model.train()  # 设置模型为训练模式\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)   # 计算模型的损失\n",
    "            optimizer.zero_grad()              # 清空梯度\n",
    "            loss.backward()                   # 反向传播计算梯度\n",
    "            optimizer.step()                  # 更新参数\n",
    "            loop.set_description(f\"epoch{epoch}\")\n",
    "            loop.set_postfix(loss=loss.cpu().detach().numpy())\n",
    "            train_loss_sum += loss.item()\n",
    "            _, predicts = torch.max(outputs.data, dim=1)  # 获取每行最大值的索引，即预测的类别\n",
    "            train_accuracy_total += labels.size(0)\n",
    "            train_correct += (predicts == labels).cpu().sum().item()\n",
    "\n",
    "        test_acc = evaluate_accuracy(test_loader, model)  # 在测试集上评估准确度\n",
    "        print(f'训练周期:{epoch},   损失:{train_loss_sum/len(data_loader):.4f},   训练准确度:{train_correct/train_accuracy_total:.3f},  测试准确度:{test_acc:.3f}')\n",
    "        torch.save(model,f\"VGG-19-{epoch}.pt\")\n",
    "\n",
    "    print('------------训练完成-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前训练周期 = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch0:   0%|          | 2/1875 [00:18<4:48:39,  9.25s/it, loss=2.3042238]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(data_loader, optimizer, loss_fn, epochs, device)\u001b[0m\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()                  \u001b[38;5;66;03m# 更新参数\u001b[39;00m\n\u001b[0;32m     19\u001b[0m loop\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m loop\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     21\u001b[0m train_loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     22\u001b[0m _, predicts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 获取每行最大值的索引，即预测的类别\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_loader, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./VGG-19-0.pt\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image size: torch.Size([1, 1, 224, 224])\n",
      "Model output size: torch.Size([1, 10])\n",
      "Model output size: tensor([[ 0.8151,  1.7634,  0.0844, -3.0375,  1.5822, -1.5031, -0.3473, -2.6272,\n",
      "          3.2717, -1.1934]], device='cuda:0')\n",
      "Input image size: torch.Size([1, 1, 224, 224])\n",
      "Model output size: torch.Size([1, 10])\n",
      "Model output size: tensor([[ 0.8216,  1.7584,  0.0825, -3.0422,  1.5899, -1.5076, -0.3442, -2.6251,\n",
      "          3.2693, -1.1917]], device='cuda:0')\n",
      "Input image size: torch.Size([1, 1, 224, 224])\n",
      "Model output size: torch.Size([1, 10])\n",
      "Model output size: tensor([[ 0.9087,  1.6903,  0.0501, -3.0874,  1.6221, -1.5084, -0.3379, -2.6022,\n",
      "          3.2263, -1.1632]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "class HandwritingRecognitionApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        self.master.title(\"手写识别应用\")\n",
    "\n",
    "        self.canvas = tk.Canvas(self.master, width=200, height=200, bg=\"white\")\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw)\n",
    "\n",
    "        self.label_result = tk.Label(self.master, text=\"预测结果: \")\n",
    "        self.label_result.pack()\n",
    "\n",
    "        self.button_predict = tk.Button(self.master, text=\"预测\", command=self.predict)\n",
    "        self.button_predict.pack()\n",
    "\n",
    "        self.button_clear = tk.Button(self.master, text=\"清空\", command=self.clear_canvas)\n",
    "        self.button_clear.pack()\n",
    "\n",
    "        # 加载模型\n",
    "        self.model = torch.load(\"./VGG-19-1.pt\")\n",
    "\n",
    "        # 优先选择GPU，没有则选择CPU\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        self.image = Image.new(\"L\", (200, 200), color=\"white\")\n",
    "        self.draw = ImageDraw.Draw(self.image)\n",
    "\n",
    "    def draw(self, event):\n",
    "        x1, y1 = (event.x - 1), (event.y - 1)\n",
    "        x2, y2 = (event.x + 1), (event.y + 1)\n",
    "        self.canvas.create_oval(x1, y1, x2, y2, fill=\"black\", width=5)\n",
    "        self.draw.line([x1, y1, x2, y2], fill=\"black\", width=5)\n",
    "\n",
    "    def predict(self):\n",
    "        try:\n",
    "            input_image = self.transform(self.image).unsqueeze(0).to(self.device, dtype=torch.float32)\n",
    "            print(\"Input image size:\", input_image.size())\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = self.model(input_image)\n",
    "            print(\"Model output size:\", output.size())\n",
    "            print(\"Model output size:\", output)\n",
    "            \n",
    "            _, predicted = torch.max(output, 1)\n",
    "            prediction = str(predicted.item())\n",
    "            self.label_result.config(text=\"Prediction: \" + prediction)\n",
    "        except Exception as e:\n",
    "            self.label_result.config(text=\"Prediction failed. Error: \" + str(e))\n",
    "\n",
    "    def clear_canvas(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.image = Image.new(\"L\", (500, 500), color=\"white\")\n",
    "        self.draw = ImageDraw.Draw(self.image)\n",
    "        self.label_result.config(text=\"Prediction: \")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = HandwritingRecognitionApp(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

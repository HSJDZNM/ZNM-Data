{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape   #有60000张图,每张是28*28像素大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape   #60000表示那60000张图片分别表示什么数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "for k in range(12):\n",
    "    plt.subplot(3, 4, k+1)\n",
    "    plt.imshow(X_train[k], cmap='Greys')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2115098de70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_valid[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 222, 254, 254, 254, 254, 241, 198,\n",
       "        198, 198, 198, 198, 198, 198, 198, 170,  52,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  67, 114,  72, 114, 163, 227, 254,\n",
       "        225, 254, 254, 254, 250, 229, 254, 254, 140,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66,\n",
       "         14,  67,  67,  67,  59,  21, 236, 254, 106,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  83, 253, 209,  18,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 133, 254, 187,   5,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   9, 205, 248,  58,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 126, 254, 182,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  75, 251, 240,  57,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         19, 221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "        203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38,\n",
       "        254, 254,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 224,\n",
       "        254, 115,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 254,\n",
       "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 242, 254,\n",
       "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254,\n",
       "        219,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
       "         18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将图像拉伸为一维数组,并将类型转换为整数类型\n",
    "X_train = X_train.reshape(60000, 784).astype('float32')\n",
    "X_valid = X_valid.reshape(10000, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#除以255将数组里的数降到0-1之间\n",
    "X_train /= 255\n",
    "X_valid /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
       "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
       "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
       "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
       "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
       "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
       "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
       "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
       "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
       "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
       "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
       "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将代码从整数转换到独热编码\n",
    "n_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设计神经网络架构\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置代价函数为平方损失函数,使用随机梯度下降,学习率设置为0.01\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0862 - accuracy: 0.3458 - val_loss: 0.0859 - val_accuracy: 0.3508\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.3468 - val_loss: 0.0856 - val_accuracy: 0.3535\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0855 - accuracy: 0.3480 - val_loss: 0.0852 - val_accuracy: 0.3541\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0851 - accuracy: 0.3488 - val_loss: 0.0848 - val_accuracy: 0.3551\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0847 - accuracy: 0.3495 - val_loss: 0.0844 - val_accuracy: 0.3574\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0843 - accuracy: 0.3526 - val_loss: 0.0840 - val_accuracy: 0.3598\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0839 - accuracy: 0.3548 - val_loss: 0.0836 - val_accuracy: 0.3626\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0836 - accuracy: 0.3584 - val_loss: 0.0832 - val_accuracy: 0.3656\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0831 - accuracy: 0.3606 - val_loss: 0.0828 - val_accuracy: 0.3690\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0827 - accuracy: 0.3652 - val_loss: 0.0824 - val_accuracy: 0.3726\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0823 - accuracy: 0.3686 - val_loss: 0.0820 - val_accuracy: 0.3788\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0819 - accuracy: 0.3735 - val_loss: 0.0815 - val_accuracy: 0.3843\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0815 - accuracy: 0.3789 - val_loss: 0.0811 - val_accuracy: 0.3895\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0810 - accuracy: 0.3850 - val_loss: 0.0807 - val_accuracy: 0.3959\n",
      "Epoch 15/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0806 - accuracy: 0.3914 - val_loss: 0.0802 - val_accuracy: 0.4024\n",
      "Epoch 16/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0802 - accuracy: 0.3975 - val_loss: 0.0798 - val_accuracy: 0.4092\n",
      "Epoch 17/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0797 - accuracy: 0.4039 - val_loss: 0.0793 - val_accuracy: 0.4146\n",
      "Epoch 18/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0793 - accuracy: 0.4108 - val_loss: 0.0789 - val_accuracy: 0.4189\n",
      "Epoch 19/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0788 - accuracy: 0.4172 - val_loss: 0.0784 - val_accuracy: 0.4270\n",
      "Epoch 20/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0784 - accuracy: 0.4237 - val_loss: 0.0779 - val_accuracy: 0.4337\n",
      "Epoch 21/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0780 - accuracy: 0.4300 - val_loss: 0.0775 - val_accuracy: 0.4395\n",
      "Epoch 22/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.4353 - val_loss: 0.0770 - val_accuracy: 0.4458\n",
      "Epoch 23/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0770 - accuracy: 0.4407 - val_loss: 0.0766 - val_accuracy: 0.4517\n",
      "Epoch 24/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0766 - accuracy: 0.4467 - val_loss: 0.0761 - val_accuracy: 0.4570\n",
      "Epoch 25/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.4526 - val_loss: 0.0756 - val_accuracy: 0.4609\n",
      "Epoch 26/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0757 - accuracy: 0.4574 - val_loss: 0.0752 - val_accuracy: 0.4674\n",
      "Epoch 27/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0752 - accuracy: 0.4619 - val_loss: 0.0747 - val_accuracy: 0.4729\n",
      "Epoch 28/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0748 - accuracy: 0.4666 - val_loss: 0.0743 - val_accuracy: 0.4780\n",
      "Epoch 29/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0743 - accuracy: 0.4710 - val_loss: 0.0738 - val_accuracy: 0.4824\n",
      "Epoch 30/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.4762 - val_loss: 0.0733 - val_accuracy: 0.4867\n",
      "Epoch 31/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.4805 - val_loss: 0.0729 - val_accuracy: 0.4897\n",
      "Epoch 32/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0729 - accuracy: 0.4850 - val_loss: 0.0724 - val_accuracy: 0.4938\n",
      "Epoch 33/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0725 - accuracy: 0.4889 - val_loss: 0.0719 - val_accuracy: 0.4967\n",
      "Epoch 34/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0720 - accuracy: 0.4924 - val_loss: 0.0715 - val_accuracy: 0.5001\n",
      "Epoch 35/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.4968 - val_loss: 0.0710 - val_accuracy: 0.5041\n",
      "Epoch 36/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0711 - accuracy: 0.5008 - val_loss: 0.0705 - val_accuracy: 0.5075\n",
      "Epoch 37/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0707 - accuracy: 0.5041 - val_loss: 0.0701 - val_accuracy: 0.5095\n",
      "Epoch 38/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0702 - accuracy: 0.5077 - val_loss: 0.0696 - val_accuracy: 0.5133\n",
      "Epoch 39/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0698 - accuracy: 0.5106 - val_loss: 0.0692 - val_accuracy: 0.5160\n",
      "Epoch 40/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0693 - accuracy: 0.5148 - val_loss: 0.0687 - val_accuracy: 0.5190\n",
      "Epoch 41/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0688 - accuracy: 0.5177 - val_loss: 0.0682 - val_accuracy: 0.5221\n",
      "Epoch 42/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0684 - accuracy: 0.5205 - val_loss: 0.0678 - val_accuracy: 0.5255\n",
      "Epoch 43/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0679 - accuracy: 0.5238 - val_loss: 0.0673 - val_accuracy: 0.5278\n",
      "Epoch 44/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0675 - accuracy: 0.5265 - val_loss: 0.0669 - val_accuracy: 0.5321\n",
      "Epoch 45/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0671 - accuracy: 0.5303 - val_loss: 0.0664 - val_accuracy: 0.5356\n",
      "Epoch 46/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0666 - accuracy: 0.5337 - val_loss: 0.0660 - val_accuracy: 0.5387\n",
      "Epoch 47/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.5372 - val_loss: 0.0655 - val_accuracy: 0.5426\n",
      "Epoch 48/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.5397 - val_loss: 0.0651 - val_accuracy: 0.5454\n",
      "Epoch 49/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.5432 - val_loss: 0.0646 - val_accuracy: 0.5494\n",
      "Epoch 50/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.5471 - val_loss: 0.0642 - val_accuracy: 0.5530\n",
      "Epoch 51/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.5502 - val_loss: 0.0637 - val_accuracy: 0.5561\n",
      "Epoch 52/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.5535 - val_loss: 0.0633 - val_accuracy: 0.5595\n",
      "Epoch 53/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0635 - accuracy: 0.5573 - val_loss: 0.0629 - val_accuracy: 0.5627\n",
      "Epoch 54/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0631 - accuracy: 0.5605 - val_loss: 0.0624 - val_accuracy: 0.5663\n",
      "Epoch 55/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.5638 - val_loss: 0.0620 - val_accuracy: 0.5700\n",
      "Epoch 56/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.5668 - val_loss: 0.0616 - val_accuracy: 0.5742\n",
      "Epoch 57/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0619 - accuracy: 0.5703 - val_loss: 0.0611 - val_accuracy: 0.5771\n",
      "Epoch 58/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0614 - accuracy: 0.5735 - val_loss: 0.0607 - val_accuracy: 0.5806\n",
      "Epoch 59/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.5770 - val_loss: 0.0603 - val_accuracy: 0.5834\n",
      "Epoch 60/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0606 - accuracy: 0.5802 - val_loss: 0.0599 - val_accuracy: 0.5869\n",
      "Epoch 61/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0602 - accuracy: 0.5842 - val_loss: 0.0595 - val_accuracy: 0.5911\n",
      "Epoch 62/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0598 - accuracy: 0.5878 - val_loss: 0.0591 - val_accuracy: 0.5952\n",
      "Epoch 63/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0594 - accuracy: 0.5908 - val_loss: 0.0587 - val_accuracy: 0.5993\n",
      "Epoch 64/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0590 - accuracy: 0.5951 - val_loss: 0.0583 - val_accuracy: 0.6042\n",
      "Epoch 65/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.5979 - val_loss: 0.0579 - val_accuracy: 0.6086\n",
      "Epoch 66/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0582 - accuracy: 0.6014 - val_loss: 0.0575 - val_accuracy: 0.6123\n",
      "Epoch 67/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0578 - accuracy: 0.6052 - val_loss: 0.0571 - val_accuracy: 0.6159\n",
      "Epoch 68/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0575 - accuracy: 0.6090 - val_loss: 0.0567 - val_accuracy: 0.6204\n",
      "Epoch 69/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0571 - accuracy: 0.6122 - val_loss: 0.0563 - val_accuracy: 0.6251\n",
      "Epoch 70/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0567 - accuracy: 0.6159 - val_loss: 0.0559 - val_accuracy: 0.6275\n",
      "Epoch 71/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0563 - accuracy: 0.6193 - val_loss: 0.0556 - val_accuracy: 0.6310\n",
      "Epoch 72/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0560 - accuracy: 0.6231 - val_loss: 0.0552 - val_accuracy: 0.6346\n",
      "Epoch 73/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0556 - accuracy: 0.6265 - val_loss: 0.0548 - val_accuracy: 0.6392\n",
      "Epoch 74/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0552 - accuracy: 0.6303 - val_loss: 0.0545 - val_accuracy: 0.6428\n",
      "Epoch 75/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0549 - accuracy: 0.6341 - val_loss: 0.0541 - val_accuracy: 0.6471\n",
      "Epoch 76/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0545 - accuracy: 0.6382 - val_loss: 0.0537 - val_accuracy: 0.6503\n",
      "Epoch 77/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0542 - accuracy: 0.6415 - val_loss: 0.0534 - val_accuracy: 0.6546\n",
      "Epoch 78/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0538 - accuracy: 0.6450 - val_loss: 0.0530 - val_accuracy: 0.6582\n",
      "Epoch 79/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0535 - accuracy: 0.6488 - val_loss: 0.0527 - val_accuracy: 0.6622\n",
      "Epoch 80/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0531 - accuracy: 0.6528 - val_loss: 0.0523 - val_accuracy: 0.6654\n",
      "Epoch 81/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0528 - accuracy: 0.6563 - val_loss: 0.0520 - val_accuracy: 0.6686\n",
      "Epoch 82/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0525 - accuracy: 0.6605 - val_loss: 0.0516 - val_accuracy: 0.6719\n",
      "Epoch 83/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0521 - accuracy: 0.6640 - val_loss: 0.0513 - val_accuracy: 0.6762\n",
      "Epoch 84/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0518 - accuracy: 0.6682 - val_loss: 0.0510 - val_accuracy: 0.6799\n",
      "Epoch 85/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0515 - accuracy: 0.6717 - val_loss: 0.0506 - val_accuracy: 0.6836\n",
      "Epoch 86/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0511 - accuracy: 0.6752 - val_loss: 0.0503 - val_accuracy: 0.6870\n",
      "Epoch 87/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0508 - accuracy: 0.6786 - val_loss: 0.0500 - val_accuracy: 0.6896\n",
      "Epoch 88/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0505 - accuracy: 0.6828 - val_loss: 0.0496 - val_accuracy: 0.6959\n",
      "Epoch 89/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0502 - accuracy: 0.6862 - val_loss: 0.0493 - val_accuracy: 0.6993\n",
      "Epoch 90/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0498 - accuracy: 0.6902 - val_loss: 0.0490 - val_accuracy: 0.7030\n",
      "Epoch 91/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0495 - accuracy: 0.6937 - val_loss: 0.0487 - val_accuracy: 0.7067\n",
      "Epoch 92/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0492 - accuracy: 0.6976 - val_loss: 0.0483 - val_accuracy: 0.7098\n",
      "Epoch 93/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0489 - accuracy: 0.7020 - val_loss: 0.0480 - val_accuracy: 0.7134\n",
      "Epoch 94/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0486 - accuracy: 0.7065 - val_loss: 0.0477 - val_accuracy: 0.7177\n",
      "Epoch 95/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0483 - accuracy: 0.7110 - val_loss: 0.0474 - val_accuracy: 0.7233\n",
      "Epoch 96/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0480 - accuracy: 0.7153 - val_loss: 0.0471 - val_accuracy: 0.7283\n",
      "Epoch 97/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0477 - accuracy: 0.7200 - val_loss: 0.0468 - val_accuracy: 0.7324\n",
      "Epoch 98/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0474 - accuracy: 0.7244 - val_loss: 0.0465 - val_accuracy: 0.7378\n",
      "Epoch 99/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0471 - accuracy: 0.7295 - val_loss: 0.0462 - val_accuracy: 0.7416\n",
      "Epoch 100/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0468 - accuracy: 0.7335 - val_loss: 0.0459 - val_accuracy: 0.7450\n",
      "Epoch 101/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.7385 - val_loss: 0.0456 - val_accuracy: 0.7501\n",
      "Epoch 102/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0462 - accuracy: 0.7431 - val_loss: 0.0453 - val_accuracy: 0.7542\n",
      "Epoch 103/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0459 - accuracy: 0.7474 - val_loss: 0.0450 - val_accuracy: 0.7583\n",
      "Epoch 104/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0456 - accuracy: 0.7519 - val_loss: 0.0447 - val_accuracy: 0.7635\n",
      "Epoch 105/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0453 - accuracy: 0.7565 - val_loss: 0.0444 - val_accuracy: 0.7679\n",
      "Epoch 106/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0450 - accuracy: 0.7602 - val_loss: 0.0441 - val_accuracy: 0.7720\n",
      "Epoch 107/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0447 - accuracy: 0.7648 - val_loss: 0.0438 - val_accuracy: 0.7752\n",
      "Epoch 108/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0444 - accuracy: 0.7690 - val_loss: 0.0435 - val_accuracy: 0.7785\n",
      "Epoch 109/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0442 - accuracy: 0.7723 - val_loss: 0.0432 - val_accuracy: 0.7813\n",
      "Epoch 110/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0439 - accuracy: 0.7761 - val_loss: 0.0429 - val_accuracy: 0.7859\n",
      "Epoch 111/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0436 - accuracy: 0.7799 - val_loss: 0.0427 - val_accuracy: 0.7892\n",
      "Epoch 112/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0433 - accuracy: 0.7832 - val_loss: 0.0424 - val_accuracy: 0.7924\n",
      "Epoch 113/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0430 - accuracy: 0.7865 - val_loss: 0.0421 - val_accuracy: 0.7959\n",
      "Epoch 114/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0428 - accuracy: 0.7893 - val_loss: 0.0418 - val_accuracy: 0.7986\n",
      "Epoch 115/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0425 - accuracy: 0.7922 - val_loss: 0.0415 - val_accuracy: 0.8018\n",
      "Epoch 116/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0422 - accuracy: 0.7951 - val_loss: 0.0413 - val_accuracy: 0.8038\n",
      "Epoch 117/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.7977 - val_loss: 0.0410 - val_accuracy: 0.8068\n",
      "Epoch 118/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.7998 - val_loss: 0.0407 - val_accuracy: 0.8091\n",
      "Epoch 119/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.8023 - val_loss: 0.0405 - val_accuracy: 0.8105\n",
      "Epoch 120/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.8049 - val_loss: 0.0402 - val_accuracy: 0.8131\n",
      "Epoch 121/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0409 - accuracy: 0.8069 - val_loss: 0.0399 - val_accuracy: 0.8158\n",
      "Epoch 122/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0406 - accuracy: 0.8087 - val_loss: 0.0397 - val_accuracy: 0.8174\n",
      "Epoch 123/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0404 - accuracy: 0.8103 - val_loss: 0.0394 - val_accuracy: 0.8190\n",
      "Epoch 124/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.8126 - val_loss: 0.0391 - val_accuracy: 0.8208\n",
      "Epoch 125/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0399 - accuracy: 0.8144 - val_loss: 0.0389 - val_accuracy: 0.8232\n",
      "Epoch 126/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0396 - accuracy: 0.8160 - val_loss: 0.0386 - val_accuracy: 0.8256\n",
      "Epoch 127/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0394 - accuracy: 0.8176 - val_loss: 0.0384 - val_accuracy: 0.8275\n",
      "Epoch 128/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0391 - accuracy: 0.8194 - val_loss: 0.0381 - val_accuracy: 0.8285\n",
      "Epoch 129/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0389 - accuracy: 0.8201 - val_loss: 0.0379 - val_accuracy: 0.8299\n",
      "Epoch 130/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0386 - accuracy: 0.8218 - val_loss: 0.0377 - val_accuracy: 0.8307\n",
      "Epoch 131/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0384 - accuracy: 0.8232 - val_loss: 0.0374 - val_accuracy: 0.8322\n",
      "Epoch 132/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0382 - accuracy: 0.8243 - val_loss: 0.0372 - val_accuracy: 0.8336\n",
      "Epoch 133/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0379 - accuracy: 0.8255 - val_loss: 0.0369 - val_accuracy: 0.8351\n",
      "Epoch 134/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0377 - accuracy: 0.8269 - val_loss: 0.0367 - val_accuracy: 0.8362\n",
      "Epoch 135/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.8278 - val_loss: 0.0365 - val_accuracy: 0.8379\n",
      "Epoch 136/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0372 - accuracy: 0.8291 - val_loss: 0.0362 - val_accuracy: 0.8397\n",
      "Epoch 137/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0370 - accuracy: 0.8303 - val_loss: 0.0360 - val_accuracy: 0.8400\n",
      "Epoch 138/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0368 - accuracy: 0.8313 - val_loss: 0.0358 - val_accuracy: 0.8411\n",
      "Epoch 139/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0366 - accuracy: 0.8323 - val_loss: 0.0356 - val_accuracy: 0.8423\n",
      "Epoch 140/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0364 - accuracy: 0.8330 - val_loss: 0.0354 - val_accuracy: 0.8431\n",
      "Epoch 141/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.8338 - val_loss: 0.0351 - val_accuracy: 0.8438\n",
      "Epoch 142/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0359 - accuracy: 0.8347 - val_loss: 0.0349 - val_accuracy: 0.8449\n",
      "Epoch 143/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0357 - accuracy: 0.8357 - val_loss: 0.0347 - val_accuracy: 0.8459\n",
      "Epoch 144/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0355 - accuracy: 0.8364 - val_loss: 0.0345 - val_accuracy: 0.8465\n",
      "Epoch 145/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.8371 - val_loss: 0.0343 - val_accuracy: 0.8479\n",
      "Epoch 146/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0351 - accuracy: 0.8378 - val_loss: 0.0341 - val_accuracy: 0.8484\n",
      "Epoch 147/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0349 - accuracy: 0.8383 - val_loss: 0.0339 - val_accuracy: 0.8490\n",
      "Epoch 148/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0347 - accuracy: 0.8390 - val_loss: 0.0337 - val_accuracy: 0.8493\n",
      "Epoch 149/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.8396 - val_loss: 0.0335 - val_accuracy: 0.8502\n",
      "Epoch 150/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0343 - accuracy: 0.8403 - val_loss: 0.0333 - val_accuracy: 0.8506\n",
      "Epoch 151/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0341 - accuracy: 0.8409 - val_loss: 0.0331 - val_accuracy: 0.8512\n",
      "Epoch 152/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.8418 - val_loss: 0.0329 - val_accuracy: 0.8521\n",
      "Epoch 153/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.8425 - val_loss: 0.0328 - val_accuracy: 0.8529\n",
      "Epoch 154/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.8430 - val_loss: 0.0326 - val_accuracy: 0.8534\n",
      "Epoch 155/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.8437 - val_loss: 0.0324 - val_accuracy: 0.8543\n",
      "Epoch 156/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0332 - accuracy: 0.8442 - val_loss: 0.0322 - val_accuracy: 0.8552\n",
      "Epoch 157/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.8447 - val_loss: 0.0320 - val_accuracy: 0.8554\n",
      "Epoch 158/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0329 - accuracy: 0.8451 - val_loss: 0.0319 - val_accuracy: 0.8558\n",
      "Epoch 159/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0327 - accuracy: 0.8457 - val_loss: 0.0317 - val_accuracy: 0.8561\n",
      "Epoch 160/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0325 - accuracy: 0.8460 - val_loss: 0.0315 - val_accuracy: 0.8569\n",
      "Epoch 161/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0323 - accuracy: 0.8465 - val_loss: 0.0313 - val_accuracy: 0.8573\n",
      "Epoch 162/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.8469 - val_loss: 0.0312 - val_accuracy: 0.8575\n",
      "Epoch 163/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0320 - accuracy: 0.8476 - val_loss: 0.0310 - val_accuracy: 0.8580\n",
      "Epoch 164/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.8481 - val_loss: 0.0308 - val_accuracy: 0.8584\n",
      "Epoch 165/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.8485 - val_loss: 0.0307 - val_accuracy: 0.8588\n",
      "Epoch 166/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.8490 - val_loss: 0.0305 - val_accuracy: 0.8594\n",
      "Epoch 167/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.8498 - val_loss: 0.0304 - val_accuracy: 0.8597\n",
      "Epoch 168/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.8501 - val_loss: 0.0302 - val_accuracy: 0.8604\n",
      "Epoch 169/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0311 - accuracy: 0.8504 - val_loss: 0.0301 - val_accuracy: 0.8612\n",
      "Epoch 170/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.8511 - val_loss: 0.0299 - val_accuracy: 0.8617\n",
      "Epoch 171/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.8513 - val_loss: 0.0298 - val_accuracy: 0.8625\n",
      "Epoch 172/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0306 - accuracy: 0.8520 - val_loss: 0.0296 - val_accuracy: 0.8629\n",
      "Epoch 173/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0305 - accuracy: 0.8523 - val_loss: 0.0295 - val_accuracy: 0.8636\n",
      "Epoch 174/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0303 - accuracy: 0.8527 - val_loss: 0.0293 - val_accuracy: 0.8639\n",
      "Epoch 175/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.8532 - val_loss: 0.0292 - val_accuracy: 0.8642\n",
      "Epoch 176/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.8538 - val_loss: 0.0291 - val_accuracy: 0.8647\n",
      "Epoch 177/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.8544 - val_loss: 0.0289 - val_accuracy: 0.8649\n",
      "Epoch 178/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.8550 - val_loss: 0.0288 - val_accuracy: 0.8652\n",
      "Epoch 179/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.8553 - val_loss: 0.0287 - val_accuracy: 0.8658\n",
      "Epoch 180/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.8557 - val_loss: 0.0285 - val_accuracy: 0.8664\n",
      "Epoch 181/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.8561 - val_loss: 0.0284 - val_accuracy: 0.8668\n",
      "Epoch 182/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.8566 - val_loss: 0.0283 - val_accuracy: 0.8674\n",
      "Epoch 183/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.8571 - val_loss: 0.0281 - val_accuracy: 0.8675\n",
      "Epoch 184/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.8575 - val_loss: 0.0280 - val_accuracy: 0.8674\n",
      "Epoch 185/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0289 - accuracy: 0.8578 - val_loss: 0.0279 - val_accuracy: 0.8677\n",
      "Epoch 186/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.8583 - val_loss: 0.0278 - val_accuracy: 0.8678\n",
      "Epoch 187/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.8587 - val_loss: 0.0276 - val_accuracy: 0.8679\n",
      "Epoch 188/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.8590 - val_loss: 0.0275 - val_accuracy: 0.8685\n",
      "Epoch 189/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0284 - accuracy: 0.8595 - val_loss: 0.0274 - val_accuracy: 0.8687\n",
      "Epoch 190/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0283 - accuracy: 0.8599 - val_loss: 0.0273 - val_accuracy: 0.8692\n",
      "Epoch 191/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.8602 - val_loss: 0.0272 - val_accuracy: 0.8700\n",
      "Epoch 192/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.8606 - val_loss: 0.0271 - val_accuracy: 0.8704\n",
      "Epoch 193/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.8610 - val_loss: 0.0270 - val_accuracy: 0.8707\n",
      "Epoch 194/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0279 - accuracy: 0.8612 - val_loss: 0.0268 - val_accuracy: 0.8714\n",
      "Epoch 195/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0277 - accuracy: 0.8616 - val_loss: 0.0267 - val_accuracy: 0.8719\n",
      "Epoch 196/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0276 - accuracy: 0.8620 - val_loss: 0.0266 - val_accuracy: 0.8723\n",
      "Epoch 197/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0275 - accuracy: 0.8624 - val_loss: 0.0265 - val_accuracy: 0.8725\n",
      "Epoch 198/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0274 - accuracy: 0.8626 - val_loss: 0.0264 - val_accuracy: 0.8725\n",
      "Epoch 199/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0273 - accuracy: 0.8627 - val_loss: 0.0263 - val_accuracy: 0.8727\n",
      "Epoch 200/200\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0272 - accuracy: 0.8630 - val_loss: 0.0262 - val_accuracy: 0.8730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21160eaabc0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/313 [..............................] - ETA: 5s - loss: 0.0235 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.8730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02621365897357464, 0.8730000257492065]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0272 - accuracy: 0.8633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02716977149248123, 0.8632833361625671]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
